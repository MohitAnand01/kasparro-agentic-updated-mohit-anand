ğŸ“˜ Multi-Agent Content Generation System
LangChain + LangGraph | Applied AI Engineer Challenge

Author: Mohit Anand

ğŸš€ 1. Problem Statement

Develop a modular agentic automation system capable of transforming a small product dataset into:

ğŸŸ¦ Product Description Page

ğŸŸ© FAQ Page (15+ structured questions & answers)

ğŸŸ¥ Comparison Page

ğŸŸ¨ Normalized JSON Outputs

âœ… System Requirements

The system must:

Use multiple, independently functioning agents

Demonstrate a clear orchestration / automation flow

Utilize reusable logic blocks

Use a custom template engine

Produce machine-readable JSON outputs

Use only the provided dataset (no external facts or internet lookup)

ğŸ¯ Evaluation Focus

Architecture & system design

Multi-agent orchestration

Modularity & reusability

Structured deterministic output

ğŸ§  2. Solution Overview

The solution is a four-agent deterministic architecture orchestrated via LangChain.

Each agent performs a single responsibility, enabling:
âœ” Maintainability
âœ” Determinism
âœ” Testability
âœ” Extensibility

ğŸ”§ 2.1 The Four Core Agents
1ï¸âƒ£ Parser Agent

Validates raw JSON

Ensures required fields exist

Converts dataset into a strict normalized schema

Initializes PageContext shared across agents

2ï¸âƒ£ Question Generation Agent

Produces 15+ categorized FAQs

Uses prompt logic instead of AI creativity

Categories include:

Informational

Usage

Safety

Purchase

Comparison

3ï¸âƒ£ FAQ Answering Agent

Answers each FAQ using only the provided product facts

Zero hallucination

Output schema:

{
  "question": "...",
  "answer": "...",
  "category": "..."
}

4ï¸âƒ£ Page Assembler Agent

Uses templates + logic rules to generate:

Product Page JSON

FAQ JSON

Comparison Page JSON

Enforces strict schemas

Powered by Jinja2 template engine

ğŸ“¦ 3. Scope & Assumptions
âœ”ï¸ In Scope

Parsing & validating provided dataset

FAQ generation (â‰¥ 15)

Fact-based FAQ answering

Template-driven page assembly

Strict JSON output

Offline execution

âŒ Out of Scope

Internet access / external data sources

Creative rewriting or LLM hallucinations

UI / frontend

Dataset expansion

ğŸ“Œ Assumptions

Dataset always follows expected schema

System should remain modular for future upgrades

No external facts may be introduced

ğŸ—ï¸ 4. System Design

The system follows a four-stage agentic pipeline, each transforming the data before passing it forward. Outputs are stored in an evolving shared PageContext.

ğŸ–¥ï¸ 4.1 High-Level System Architecture
flowchart LR

    subgraph INPUT[Input Layer]
        A[Raw Product JSON]
    end

    subgraph AGENTS[Agent Layer]
        P[Parser Agent<br/>Normalize + Validate Schema]
        QG[Question Generation Agent<br/>15+ Categorized Questions]
        ANS[FAQ Answering Agent<br/>Fact-Based Answers]
        ASM[Assembler Agent<br/>Templates + Logic Blocks]
    end

    subgraph LOGIC[Supporting Logic]
        LB[Reusable Logic Blocks<br/>Usage Â· Safety Â· Benefits]
        TMP[Template Engine (Jinja2)]
        VAL[Schema Validation]
    end

    subgraph OUTPUT[Output Layer]
        OP1[product_page.json]
        OP2[faq.json]
        OP3[comparison_page.json]
    end

    A --> P --> QG --> ANS --> ASM
    LB --> ASM
    TMP --> ASM
    VAL --> P

    ASM --> OP1
    ASM --> OP2
    ASM --> OP3

ğŸ”„ 4.2 Agent Workflow Pipeline
flowchart TD

    A[Raw Product JSON] --> B[Parser Agent<br/>Normalize & Validate Schema]
    B --> C[Question Generation Agent<br/>Generate 15+ Categorized FAQs]
    C --> D[FAQ Answering Agent<br/>Answer Using Product Facts Only]
    D --> E[Assembler Agent<br/>Build Product Â· FAQ Â· Comparison Pages]

    E --> F1[product_page.json]
    E --> F2[faq.json]
    E --> F3[comparison_page.json]

ğŸ“ 5. Folder Structure (GitHub-Ready)
src/
 â”œâ”€â”€ agents/
 â”‚    â”œâ”€â”€ langchain_agent_system.py
 â”‚    â””â”€â”€ langchain_pipeline.py
 â”œâ”€â”€ tools/
 â”‚    â”œâ”€â”€ llm_tools.py
 â”‚    â””â”€â”€ file_tools.py
 â”œâ”€â”€ prompts/
 â”‚    â”œâ”€â”€ parser_prompt.txt
 â”‚    â”œâ”€â”€ qgen_prompt.txt
 â”‚    â”œâ”€â”€ planner_prompt.txt
 â”‚    â””â”€â”€ assembler_prompt.txt
 â”œâ”€â”€ templates/
 â”‚    â””â”€â”€ product_template.j2
 â”œâ”€â”€ data/
 â”‚    â””â”€â”€ product_input.json
 â”œâ”€â”€ main.py
 â””â”€â”€ __init__.py

outputs/
 â”œâ”€â”€ product_page.json
 â”œâ”€â”€ faq.json
 â””â”€â”€ comparison_page.json

âš™ï¸ 6. Execution Flow
Step 1 â€” Load Input JSON

Loads product_input.json.

Step 2 â€” Parser Agent

Validates â†’ Normalizes â†’ Creates internal schema.

Step 3 â€” Question Generation Agent

Produces 15+ structured questions.

Step 4 â€” FAQ Answering Agent

Answers questions using only product data.

Step 5 â€” Assembler Agent

Uses templates + logic blocks to create output pages.

Step 6 â€” File Writer Tool

Exports all three pages as JSON.

ğŸ§° 7. Tech Stack
Component	Technology
Agent Framework	LangChain
Optional Orchestration	LangGraph
LLM Backend	HuggingFace (flan-t5-small, distilgpt2)
Prompt Engine	LangChain PromptTemplate
Template Engine	Jinja2
Output Format	JSON
Language	Python 3.10+
ğŸ† 8. Why This Solution Meets All Requirements

âœ” Multi-agent architecture
âœ” Framework-driven agent orchestration
âœ” Reusable logic blocks
âœ” Custom Jinja2 template engine
âœ” Deterministic output (Mock or Local LLM mode)
âœ” Clean JSON schema enforcement
âœ” Offline-friendly
âœ” Maintainable folder structure
âœ” Zero hallucinations (facts only from product JSON)

ğŸ¯ 9. Conclusion

This project demonstrates a production-ready agentic automation pipeline powered by LangChain.
Through strict schema enforcement, modular agent design, and template-driven output generation, the system reliably produces:

Product Description Page

FAQ Page (15+ items)

Comparison Page

Structured JSON outputs

The architecture is:

Scalable

Maintainable

Deterministic

Fully challenge compliant

If you'd like:
âœ… A PDF-ready version
âœ… A GitHub Pages documentation version
âœ… A compressed 1-page executive summary

Just tell me!
